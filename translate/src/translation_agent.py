"""
æ™ºèƒ½ç¿»è¯‘ä»£ç†
"""

import os
from typing import Dict, Optional, List, Tuple
from pathlib import Path
import json

from .markdown_parser import MarkdownParser, Metadata
from .translator import SmartTranslator
from .text_chunker import MarkdownChunker


class TranslationAgent:
    """æ™ºèƒ½ç¿»è¯‘ä»£ç†"""
    
    def __init__(self, 
                 model_name: str = "gpt-3.5-turbo",
                 translator_id: str = "FILL_YOUR_GITHUB_ID_HERE",
                 max_tokens: int = 800,
                 provider: str = None,
                 openai_api_key: str = None,
                 openai_base_url: str = None,
                 qwen_api_key: str = None):
        """
        åˆå§‹åŒ–ç¿»è¯‘ä»£ç†
        """
        self.translator_id = translator_id
        self.model_name = model_name
        self.provider = provider
        self.parser = MarkdownParser()
        self.translator = SmartTranslator(
            model_name, provider=provider,
            openai_api_key=openai_api_key,
            openai_base_url=openai_base_url,
            qwen_api_key=qwen_api_key
        )
        
    def translate_file(self, 
                      input_file: str, 
                      output_file: Optional[str] = None,
                      save_stats: bool = True) -> Dict:
        """
        ç¿»è¯‘Markdownæ–‡ä»¶
        """
        if not os.path.exists(input_file):
            raise FileNotFoundError(f"è¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨: {input_file}")
        
        print(f"æ­£åœ¨å¤„ç†æ–‡ä»¶: {input_file}")

        metadata, content = self.parser.parse_file(input_file)
        
        print(f"æ–‡æ¡£æ ‡é¢˜: {metadata.title}")
        print(f"åŸä½œè€…: {metadata.author}")
        print(f"æ–‡æ¡£é•¿åº¦: {len(content)} å­—ç¬¦")
        
        translated_content, stats = self.translator.translate_content(content)

        updated_metadata = self.parser.update_translation_metadata( #å…ƒæ•°æ®æ›´æ–°1
            metadata, self.translator_id
        )
        
        if output_file is None:
            input_path = Path(input_file)
            output_file = str(input_path.parent / f"{input_path.stem}_translated.md")
        
        final_output = self.parser.format_output(updated_metadata, translated_content)
        
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write(final_output)
        
        print(f"ç¿»è¯‘å®Œæˆï¼Œè¾“å‡ºæ–‡ä»¶: {output_file}")
        
        #ç»Ÿè®¡ä¿¡æ¯
        if save_stats:
            stats_file = str(Path(output_file).with_suffix('.stats.json'))
            self._save_translation_stats(stats, stats_file)
        
        # æ·»åŠ æ–‡ä»¶è·¯å¾„åˆ°ç»Ÿè®¡ä¿¡æ¯
        stats.update({
            "input_file": input_file,
            "output_file": output_file,
            "translator_id": self.translator_id
        })
        
        return stats
    
    def translate_text(self, 
                      text: str, 
                      title: str = "FILL_THE_TITLE_HERE",
                      author: str = "FILL_THE_AUTHOR_HERE") -> Tuple[str, Dict]:
        """
        ç¿»è¯‘æ–‡æœ¬å­—ç¬¦ä¸²
        """
        metadata, content = self.parser.parse_text(text)

        if metadata.title == "FILL_THE_TITLE_HERE":
            metadata.title = title
        if metadata.author == "FILL_THE_AUTHOR_HERE":
            metadata.author = author
        
        print(f"æ­£åœ¨ç¿»è¯‘æ–‡æ¡£: {metadata.title}")

        translated_content, stats = self.translator.translate_content(content)

        updated_metadata = self.parser.update_translation_metadata(
            metadata, self.translator_id   #å…ƒæ•°æ®æ›´æ–°
        )

        final_output = self.parser.format_output(updated_metadata, translated_content)
        
        return final_output, stats
    
    def batch_translate(self, 
                       input_dir: str, 
                       output_dir: str,
                       file_pattern: str = "*.md") -> List[Dict]:
        """
        æ‰¹é‡ç¿»è¯‘æ–‡ä»¶
        """
        input_path = Path(input_dir)
        output_path = Path(output_dir)

        output_path.mkdir(parents=True, exist_ok=True)

        files = list(input_path.glob(file_pattern))
        
        if not files:
            print(f"åœ¨ {input_dir} ä¸­æ²¡æœ‰æ‰¾åˆ°åŒ¹é… {file_pattern} çš„æ–‡ä»¶")
            return []
        
        print(f"æ‰¾åˆ° {len(files)} ä¸ªæ–‡ä»¶éœ€è¦ç¿»è¯‘")
        
        results = []
        
        for file_path in files:
            print(f"\nå¤„ç†æ–‡ä»¶ {len(results) + 1}/{len(files)}: {file_path.name}")
            
            try:
                output_file = output_path / f"{file_path.stem}_translated.md"
                stats = self.translate_file(str(file_path), str(output_file))
                results.append(stats)
                
            except Exception as e:
                print(f"ç¿»è¯‘æ–‡ä»¶ {file_path} æ—¶å‡ºé”™: {e}")
                results.append({
                    "input_file": str(file_path),
                    "error": str(e),
                    "completeness_score": 0
                })

        report_file = output_path / "batch_translation_report.json"
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(results, f, ensure_ascii=False, indent=2)
        
        print(f"\næ‰¹é‡ç¿»è¯‘å®Œæˆï¼ŒæŠ¥å‘Šä¿å­˜è‡³: {report_file}")
        
        return results
    
    def _save_translation_stats(self, stats: Dict, stats_file: str):
        """
        ä¿å­˜ç¿»è¯‘ç»Ÿè®¡ä¿¡æ¯
        """
        try:
            with open(stats_file, 'w', encoding='utf-8') as f:
                json.dump(stats, f, ensure_ascii=False, indent=2)
            print(f"ç¿»è¯‘ç»Ÿè®¡ä¿¡æ¯å·²ä¿å­˜è‡³: {stats_file}")
        except Exception as e:
            print(f"ä¿å­˜ç»Ÿè®¡ä¿¡æ¯æ—¶å‡ºé”™: {e}")
    
    def get_translation_report(self, stats: Dict) -> str:
        """
        ç”Ÿæˆç¿»è¯‘æŠ¥å‘Š
        """
        report = f"""
ç¿»è¯‘å®ŒæˆæŠ¥å‘Š
================

ğŸ“Š åŸºæœ¬ä¿¡æ¯
- ç¿»è¯‘è€…: {self.translator_id}
- æ–‡æœ¬å—æ•°: {stats.get('chunk_count', 0)}
- å®Œæ•´æ€§è¯„åˆ†: {stats.get('completeness_score', 0)}/10

ğŸ“ åŸæ–‡æ‘˜è¦
{stats.get('original_summary', 'æ— ')}

ğŸ” è¯‘æ–‡æ‘˜è¦  
{stats.get('translated_summary', 'æ— ')}

âœ… è´¨é‡è¯„ä¼°
- å®Œæ•´æ€§: {stats.get('completeness_score', 0)}/10
- é—æ¼å†…å®¹: {stats.get('comparison_result', {}).get('missing_content', 'æ— ')}
- æ”¹è¿›å»ºè®®: {stats.get('comparison_result', {}).get('suggestions', 'æ— ')}

"""
        return report
    
    def validate_translation(self, original_file: str, translated_file: str) -> Dict:
        """
        éªŒè¯ç¿»è¯‘è´¨é‡
        """
        # è¯»å–åŸæ–‡å’Œè¯‘æ–‡
        _, original_content = self.parser.parse_file(original_file)
        _, translated_content = self.parser.parse_file(translated_file)
        
        # ç”Ÿæˆæ‘˜è¦å¹¶æ¯”è¾ƒ
        original_summary = self.translator.summary_generator.generate_original_summary(original_content)
        translated_summary = self.translator.summary_generator.generate_translated_summary(translated_content)
        
        comparison_result = self.translator.summary_generator.compare_summaries(
            original_summary, translated_summary
        )
        
        return {
            "original_summary": original_summary,
            "translated_summary": translated_summary,
            "comparison_result": comparison_result,
            "validation_score": comparison_result["completeness_score"]
        }